{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cProfile import label\n",
    "from re import X\n",
    "from turtle import color\n",
    "from sympy import li\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as D\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import importlib\n",
    "\n",
    "import dual_enc_dec_cnmp as dual_enc_dec_cnmp\n",
    "import utils\n",
    "importlib.reload(dual_enc_dec_cnmp)\n",
    "importlib.reload(utils)\n",
    "\n",
    "#params = np.array([[2,0],[2,0],[2,0],[2,0],[2,0],[-0.6,0.1],[-0.55, 0.16],[-0.5,0.23],[-0.45, 0.33],[-0.4,0.43]])\n",
    "params = np.array([[20],[19.9],[19.7]])\n",
    "\n",
    "num_demo = 128\n",
    "X1, X2, Y1, Y2, validation_Y1, validation_Y2 = utils.generate_demonstrations(num_demo, time_len=200, params = params, plot_title='Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data = [X1, X2, Y1, Y2]\n",
    "d_x = 1\n",
    "d_y1 = 1\n",
    "d_y2 = 1\n",
    "OBS_MAX = 30\n",
    "d_N = num_demo\n",
    "time_len = 200\n",
    "\n",
    "validation_indices_1 = [i+1 for i in range(0, 32, 7)]\n",
    "validation_indices_2 = [i+2 for i in range(0, 32, 7)]\n",
    "validation_indices = validation_indices_1 + validation_indices_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dual_enc_dec_cnmp)\n",
    "importlib.reload(utils)\n",
    "\n",
    "\n",
    "errors = []\n",
    "losses = []\n",
    "\n",
    "def train():\n",
    "\n",
    "    model = dual_enc_dec_cnmp.DualEncoderDecoder(d_x, d_y1, d_y2).double()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    def lr_lambda(epoch):\n",
    "        if epoch < 50000:\n",
    "            return 1e-3 / optimizer.defaults['lr']  # Scale factor for 1e-3\n",
    "        elif 50000 <= epoch < 100000:\n",
    "            return 1e-4 / optimizer.defaults['lr']  # Scale factor for 1e-4\n",
    "        else:\n",
    "            return 1e-5 / optimizer.defaults['lr']  # Scale factor for 1e-5\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "    error = 0\n",
    "\n",
    "    for i in range(EPOCHS):\n",
    "\n",
    "        obs, x_tar, y_tar = dual_enc_dec_cnmp.get_training_sample(validation_indices, X1, Y1, X2, Y2, OBS_MAX, d_N, d_x, d_y1, d_y2, time_len)\n",
    "        #print(np.array(x_tar).shape)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(obs, x_tar)\n",
    "        #print(np.array(y_tar).shape)\n",
    "        loss = dual_enc_dec_cnmp.log_prob_loss(output, y_tar, d_y1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            if i % 100 == 0:\n",
    "                \n",
    "                # print(f'Epoch: {i}, Loss: {loss.item()}')\n",
    "                error = 0\n",
    "                plot_id = np.random.randint(0, len(validation_indices))\n",
    "                for validation_idx in validation_indices:\n",
    "                    time = np.linspace(0, 1, time_len)\n",
    "                    # permute time\n",
    "                    idx = np.random.permutation(time_len)\n",
    "                    idx = idx[:OBS_MAX]\n",
    "                    time = [time[i] for i in idx]\n",
    "                    condition_points = [[t, Y1[validation_idx, i:i+1]] for t,i in zip(time, idx)]\n",
    "                    means, stds = dual_enc_dec_cnmp.predict_inverse(model, validation_idx, time_len, condition_points, d_x, d_y1, d_y2, demo_data)\n",
    "                    if i % 10000 == 0 and validation_idx == validation_indices[plot_id]:\n",
    "                        error += utils.validate_model(means, stds, validation_idx, demo_data, time_len, condition_points, i, plot=True)\n",
    "                    else:\n",
    "                        error += utils.validate_model(means, stds, validation_idx, demo_data, time_len, condition_points, i, plot=False)\n",
    "                errors.append(error)\n",
    "                if error == min(errors):\n",
    "                    print('Saving model ', i)\n",
    "                    torch.save(model.state_dict(), 'inverse_best_model.pth')\n",
    "                \n",
    "                \n",
    "                losses.append(loss.item())\n",
    "                \"\"\"\n",
    "                if loss.item() == min(losses):\n",
    "                    print('Saving model ', i)\n",
    "                    torch.save(model.state_dict(), 'inverse_best_model.pth')\n",
    "                \"\"\"\n",
    "                \n",
    "                continue\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            \"\"\"\n",
    "            if loss.item() == min(losses):\n",
    "                print('Saving model ', i)\n",
    "                torch.save(model.state_dict(), 'inverse_best_model.pth')\n",
    "            \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dual_enc_dec_cnmp)\n",
    "importlib.reload(utils)\n",
    "\n",
    "EPOCHS = 500000\n",
    "learning_rate = 1e-3\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dual_enc_dec_cnmp)\n",
    "importlib.reload(utils)\n",
    "\n",
    "best_model = dual_enc_dec_cnmp.DualEncoderDecoder(d_x, d_y1, d_y2).double()\n",
    "best_model.load_state_dict(torch.load('inverse_best_model.pth'))\n",
    "\n",
    "t = 0.25\n",
    "min_y_f = np.min(Y1[:, int(t * time_len)])\n",
    "max_y_f = np.max(Y1[:, int(t * time_len)])\n",
    "interval_y_f = np.linspace(min_y_f-0.1, max_y_f+0.1, 20)\n",
    "\n",
    "min_y_i = np.min(Y2[:, int(t * time_len)])\n",
    "max_y_i = np.max(Y2[:, int(t * time_len)])\n",
    "interval_y_i = np.linspace(min_y_i-0.1, max_y_i+0.1, 20)\n",
    "\n",
    "i = 0\n",
    "for idx in interval_y_f:\n",
    "    condition_points = [[t, idx]]\n",
    "    means, stds = dual_enc_dec_cnmp.predict_inverse(best_model, 1, time_len, condition_points, d_x, d_y1, d_y2, demo_data)\n",
    "    if i == 0:\n",
    "        utils.plot_results(means, stds, Y1, Y2, idx, condition_points, errors, losses, time_len, d_N, plot_errors = True)\n",
    "        i += 1\n",
    "    utils.plot_results(means, stds, Y1, Y2, idx, condition_points, errors, losses, time_len, d_N, plot_errors = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dual_enc_dec_cnmp)\n",
    "importlib.reload(utils)\n",
    "\n",
    "best_model = dual_enc_dec_cnmp.DualEncoderDecoder(d_x, d_y1, d_y2).double()\n",
    "best_model.load_state_dict(torch.load('inverse_best_model.pth'))\n",
    "\n",
    "\n",
    "num_validate = 10\n",
    "num_obs = 30\n",
    "freq = 0.\n",
    "def dist(amplitude, x):\n",
    "    #return amplitude * math.sin(2 * torch.pi * freq * x + 0)\n",
    "    if x<0.5: #or True:\n",
    "        return -amplitude * x + amplitude * (1-x)\n",
    "    else:\n",
    "        return -amplitude * math.sin(2 * math.pi * 2 * x + 0)\n",
    "    \n",
    "amplitudes = np.linspace(0.75,1.0,num_validate)\n",
    "times = np.linspace(0,1,num_obs)\n",
    "\n",
    "condition_point_set = []\n",
    "for i in range(num_validate):\n",
    "    condition_point_set.append([])\n",
    "    for j in range(num_obs):\n",
    "        condition_point_set[-1].append([times[j], dist(amplitudes[i], times[j])])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(condition_point_set)):\n",
    "    condition_points = condition_point_set[i]\n",
    "    means, stds = dual_enc_dec_cnmp.predict_inverse(best_model, 0, time_len, condition_points, d_x, d_y1, d_y2, demo_data)\n",
    "    if i == 0:\n",
    "        utils.plot_results(means, stds, Y1, Y2, idx, condition_points, errors, losses, time_len, d_N, plot_errors = True, test_dist =(dist,i,num_validate))\n",
    "    utils.plot_results(means, stds, Y1, Y2, idx, condition_points, errors, losses, time_len, d_N, plot_errors = False, test_dist = (dist,i,num_validate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importlib.reload(dual_enc_dec_cnmp)\n",
    "importlib.reload(utils)\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "t = 0.25\n",
    "min_y_f = np.min(Y1[:, int(t * time_len)])\n",
    "max_y_f = np.max(Y1[:, int(t * time_len)])\n",
    "interval_y_f = np.linspace(min_y_f, max_y_f, 20)\n",
    "\n",
    "min_y_i = np.min(Y2[:, int(t * time_len)])\n",
    "max_y_i = np.max(Y2[:, int(t * time_len)])\n",
    "interval_y_i = np.linspace(min_y_i, max_y_i, 20)\n",
    "\n",
    "## perform PCA on the latent space\n",
    "observations_f = torch.tensor([[t, y] for y in interval_y_f])\n",
    "observations_i = torch.tensor([[t, y] for y in interval_y_i])\n",
    "\n",
    "pca_result = dual_enc_dec_cnmp.plot_latent_space(best_model, observations_f, observations_i)\n",
    "\n",
    "## open 2 subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 7))\n",
    "\n",
    "## add a horizontal line at t = 0.25\n",
    "for i in range(2):\n",
    "    axs[i].axvline(x=t, color='r', linestyle='--')\n",
    "\n",
    "for forward_traj in Y1:\n",
    "    axs[0].plot(np.linspace(0, 1, time_len), forward_traj, c='black', alpha=0.2)\n",
    "for inverse_traj in Y2:\n",
    "    axs[1].plot(np.linspace(0, 1, time_len), inverse_traj, c='black', alpha=0.2)\n",
    "axs[0].set_title(\"Forward trajectories and observations\")\n",
    "axs[1].set_title(\"Inverse trajectories and observations\")\n",
    "for i in range(len(interval_y_f) + len(interval_y_i)):\n",
    "    point = pca_result[i]\n",
    "    if i < 20:\n",
    "        if i == 0:\n",
    "            axs[0].scatter(t, interval_y_f[i], c=f\"{(i)/(1.4*len(interval_y_f))}\", label = f\"Forward observation, smallest amplitude at t = {t}\")\n",
    "            continue\n",
    "        if i == 19:\n",
    "            axs[0].scatter(t, interval_y_f[i], c=f\"{(i)/(1.4*len(interval_y_f))}\", label = f\"Forward observation, greatest amplitude at t = {t}\")\n",
    "            continue\n",
    "        axs[0].scatter(t, interval_y_f[i], c=f\"{(i)/(1.4*len(interval_y_f))}\")#, label = f\"forward\")\n",
    "    else:\n",
    "        if i == 20:\n",
    "            axs[1].scatter(t, interval_y_i[i-20], c=f\"{(39-i)/(1.4*len(interval_y_f))}\", marker=\"^\", label = f\"Inverse observation, smallest amplitude at t = {t}\")\n",
    "            continue\n",
    "        if i == 39:\n",
    "            axs[1].scatter(t, interval_y_i[i-20], c=f\"{(39-i)/(1.4*len(interval_y_f))}\", marker=\"^\", label = f\"Inverse observation, greatest amplitude at t = {t}\")\n",
    "        axs[1].scatter(t, interval_y_i[i-20], c=f\"{(39-i)/(1.4*len(interval_y_f))}\", marker=\"^\")#, label = f\"inverse\")\n",
    "\n",
    "# plot 3d\n",
    "for i in range(len(interval_y_f) + len(interval_y_i)):\n",
    "    point = pca_result[i]\n",
    "    #plot 3d\n",
    "    if i < 20:\n",
    "        if i == 0:\n",
    "            axs[2].scatter(point[0], point[1], c=f\"{(i)/(1.4*len(interval_y_f))}\", label = f\"Forward observation, smallest amplitude at t = {t}\")\n",
    "            continue\n",
    "        if i == 19:\n",
    "            axs[2].scatter(point[0], point[1], c=f\"{(i)/(1.4*len(interval_y_f))}\", label = f\"Forward observation, greatest amplitude at t = {t}\")\n",
    "            continue\n",
    "        plt.scatter(point[0], point[1], c=f\"{(i)/(1.4*len(interval_y_f))}\")#, label = f\"forward\")\n",
    "    else:\n",
    "        if i == 20:\n",
    "            axs[2].scatter(point[0], point[1], c=f\"{(39-i)/(1.4*len(interval_y_f))}\", marker=\"^\", label = f\"Inverse observation, greatest amplitude at t = {t}\")\n",
    "            continue\n",
    "        if i == 39:\n",
    "            axs[2].scatter(point[0], point[1], c=f\"{(39-i)/(1.4*len(interval_y_f))}\", marker=\"^\", label = f\"Inverse observation, smallest amplitude at t = {t}\")\n",
    "        axs[2].scatter(point[0], point[1], c=f\"{(39-i)/(1.4*len(interval_y_f))}\", marker=\"^\")#, label = f\"inverse\")\n",
    "\n",
    "plt.title(\"PCA Analysis of the latent space of a single observation at t = 0.25\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
